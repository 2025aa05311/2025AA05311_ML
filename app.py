# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13u_vw7yCg0zTbdA9mI6YVHNCz4Qx2bSk
"""

import streamlit as st
import pandas as pd
import joblib
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, matthews_corrcoef

st.set_page_config(page_title="ML Classification Showcase", layout="wide")
st.title("ðŸ· Red Wine Quality: Classification Model Showcase")

# a. Dataset Upload (Test data only)
uploaded_file = st.file_uploader("Upload Test CSV (must contain 'quality' or 'target' column)", type="csv")

if uploaded_file:
    # Load data
    data = pd.read_csv(uploaded_file)
    st.write("### Dataset Preview", data.head())

    # Preprocessing: Separate features and target
    # We drop 'quality' and 'target' to match the 11 features used in training
    X_test_input = data.drop(['quality', 'target'], axis=1, errors='ignore')
    
    # Extract ground truth for evaluation
    if 'target' in data.columns:
        y_test_true = data['target']
    elif 'quality' in data.columns:
        y_test_true = (data['quality'] > 5).astype(int)
    else:
        st.error("Error: Uploaded file must contain 'quality' or 'target' for evaluation.")
        st.stop()

    # b. Model Selection
    st.sidebar.header("Model Settings")
    model_option = st.sidebar.selectbox("Choose a Model", 
        ["Logistic Regression", "Decision Tree", "kNN", "Naive Bayes", "Random Forest", "XGBoost"])

    model_path = f"model/{model_option.replace(' ', '_').lower()}.pkl"

    if os.path.exists(model_path):
        # Load and Predict
        model = joblib.load(model_path)
        y_pred = model.predict(X_test_input)

        # c. Display Evaluation Metrics
        st.divider()
        st.subheader(f"ðŸ“Š Performance Metrics: {model_option}")
        
        m1, m2, m3 = st.columns(3)
        m1.metric("Accuracy", f"{accuracy_score(y_test_true, y_pred):.4f}")
        m2.metric("MCC Score", f"{matthews_corrcoef(y_test_true, y_pred):.4f}")
        m3.metric("F1 Score", f"{f1_score(y_test_true, y_pred):.4f}")

        # d. Confusion Matrix & Report
        col_left, col_right = st.columns(2)
        
        with col_left:
            st.write("#### Classification Report")
            st.text(classification_report(y_test_true, y_pred))

        with col_right:
            st.write("#### Confusion Matrix")
            cm = confusion_matrix(y_test_true, y_pred)
            fig, ax = plt.subplots(figsize=(5, 4))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                        xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'])
            plt.ylabel('Actual')
            plt.xlabel('Predicted')
            st.pyplot(fig) # Use st.pyplot for matplotlib figures
    else:
        st.error(f"Model file '{model_path}' not found in the repository.")
