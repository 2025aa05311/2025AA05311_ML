# -*- coding: utf-8 -*-
"""train_model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qgrvasqfZOLRVSqwlvQRLKpI8Qo73suJ
"""

import pandas as pd
import numpy as np
import joblib
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef
import os

# Ensure model directory exists
os.makedirs('model', exist_ok=True)

# 1. Load and Explore Dataset
# Using Wine Quality Red dataset as an example
df = pd.read_csv('/content/model/winequality-red.csv', sep=';')

print("--- DATASET EXPLORATION ---")
print(f"Dataset Shape: {df.shape}")  #
print("\nFirst 5 Rows (Peek at Data):")
print(df.head())  #

print("\nFeature Information & Data Types:")
print(df.info())  #

print("\nStatistical Summary:")
print(df.describe())  #

# 2. Data Preprocessing
# Create binary target: 1 if quality > 5 (Good), else 0 (Bad)
df['target'] = (df['quality'] > 5).astype(int)

print("\nClass Distribution (Target variable):")
print(df['target'].value_counts())  #

X = df.drop(['quality', 'target'], axis=1)
y = df['target']

# Split data: 80% Train, 20% Test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Define the 6 Required Models
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(),
    "kNN": KNeighborsClassifier(),
    "Naive Bayes": GaussianNB(),
    "Random Forest(Ensemble)": RandomForestClassifier(),
    "XGBoost(Ensemble)": XGBClassifier(use_label_encoder=False, eval_metric='logloss')
}

# 4. Train, Evaluate, and Save Models
results = []
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Probabilities for AUC
    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else y_pred

    # Calculate all required metrics
    metrics = {
        "ML Model Name": name,
        "Accuracy": accuracy_score(y_test, y_pred),
        "AUC": roc_auc_score(y_test, y_prob),
        "Precision": precision_score(y_test, y_pred),
        "Recall": recall_score(y_test, y_pred),
        "F1": f1_score(y_test, y_pred),
        "MCC": matthews_corrcoef(y_test, y_pred)
    }
    results.append(metrics)

    # Save model as .pkl for Streamlit
    joblib.dump(model, f'model/{name.replace(" ", "_").lower()}.pkl')

# 5. Comparison Table for README
comparison_df = pd.DataFrame(results)
print("\n--- MODEL COMPARISON TABLE ---")
print(comparison_df.to_string(index=False))

# Export for your README.md
comparison_df.to_csv("model_comparison.csv", index=False)





